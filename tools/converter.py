# -*- coding: utf-8 -*-
# @Time    : 2021/8/25
# @Author  : Lart Pang
# @GitHub  : https://github.com/lartpang

import argparse
import re
from itertools import chain

import numpy as np
import yaml

# fmt: off
parser = argparse.ArgumentParser(description="A useful and convenient tool to convert your .npy results into the table code in latex.")
parser.add_argument("-i", "--result-file", required=True, nargs="+", action="extend", help="The path of the *_metrics.npy file.")
parser.add_argument("-o", "--tex-file", required=True, type=str, help="The path of the exported tex file.")
parser.add_argument("-c", "--config-file", type=str, help="The path of the customized config yaml file.")
parser.add_argument("--contain-table-env", action="store_true", help="Whether to containe the table env in the exported code.")
parser.add_argument("--num-bits", type=int, default=3, help="Number of valid digits.")
parser.add_argument("--transpose", action="store_true", help="Whether to transpose the table.")
# fmt: on
args = parser.parse_args()

arg_head = f"%% Generated by: {vars(args)}"


def update_dict(parent_dict, sub_dict):
    for sub_k, sub_v in sub_dict.items():
        if sub_k in parent_dict:
            if sub_v is not None and isinstance(sub_v, dict):
                update_dict(parent_dict=parent_dict[sub_k], sub_dict=sub_v)
                continue
        parent_dict.update(sub_dict)


results = {}
for result_file in args.result_file:
    result = np.load(file=result_file, allow_pickle=True).item()
    for dataset_name, method_infos in result.items():
        results.setdefault(dataset_name, {})
        for method_name, method_info in method_infos.items():
            new_method_info = {}
            for metric_name, metric_result in method_info.items():
                if "fmeasure" in metric_name:
                    metric_name = metric_name.replace("fmeasure", "f")
                new_method_info[metric_name] = metric_result
            results[dataset_name][method_name] = new_method_info

IMPOSSIBLE_UP_BOUND = 1
IMPOSSIBLE_DOWN_BOUND = 0

# 读取数据
dataset_names = sorted(list(results.keys()))
metric_names = ["SM", "wFm", "MAE", "adpE", "avgE", "maxE", "adpF", "avgF", "maxF"]
method_names = sorted(list(set(chain(*[list(results[n].keys()) for n in dataset_names]))))

if args.config_file is not None:
    assert args.config_file.endswith(".yaml") or args.config_file.endswith("yml")
    with open(args.config_file, mode="r", encoding="utf-8") as f:
        cfg = yaml.safe_load(f)

    if "dataset_names" not in cfg:
        print("`dataset_names` not in the config file, use the default config.")
    else:
        dataset_names = cfg["dataset_names"]
    if "metric_names" not in cfg:
        print("`metric_names` not in the config file, use the default config.")
    else:
        metric_names = cfg["metric_names"]
    if "method_names" not in cfg:
        print("`method_names` not in the config file, use the default config.")
    else:
        method_names = cfg["method_names"]

print(
    f"CONFIG INFORMATION:"
    f"\n- DATASETS ({len(dataset_names)}): {dataset_names}]"
    f"\n- METRICS ({len(metric_names)}): {metric_names}"
    f"\n- METHODS ({len(method_names)}): {method_names}"
)

if isinstance(metric_names, (list, tuple)):
    ori_metric_names = metric_names
elif isinstance(metric_names, dict):
    ori_metric_names, metric_names = list(zip(*list(metric_names.items())))
else:
    raise NotImplementedError

if isinstance(method_names, (list, tuple)):
    ori_method_names = method_names
elif isinstance(method_names, dict):
    ori_method_names, method_names = list(zip(*list(method_names.items())))
else:
    raise NotImplementedError

# 整理表格
ori_columns = []
column_for_index = []
for dataset_idx, dataset_name in enumerate(dataset_names):
    for metric_idx, ori_metric_name in enumerate(ori_metric_names):
        filled_value = (
            IMPOSSIBLE_UP_BOUND if ori_metric_name.lower() == "mae" else IMPOSSIBLE_DOWN_BOUND
        )
        filled_dict = {k: filled_value for k in ori_metric_names}
        ori_column = []
        for method_name in ori_method_names:
            method_result = results[dataset_name].get(method_name, filled_dict)
            if ori_metric_name not in method_result:
                raise KeyError(
                    f"{ori_metric_name} must be contained in {list(method_result.keys())}"
                )
            ori_column.append(method_result[ori_metric_name])

        column_for_index.append([x * round(1 - filled_value * 2) for x in ori_column])
        ori_columns.append(ori_column)

style_templates = dict(
    method_row_body="& {method_name}",
    method_column_body=" {method_name}",
    dataset_row_body="& \multicolumn{{{num_metrics}}}{{c}}{{\\textbf{{{dataset_name}}}}}",
    dataset_column_body="\multirow{{-{num_metrics}}}{{*}}{{\\rotatebox{{90}}{{\\textbf{{{dataset_name}}}}}}}",
    dataset_head=" ",
    metric_body="& {metric_name}",
    metric_row_head=" ",
    metric_column_head="& ",
    body=[
        "& \\first{{{txt:.03f}}}",  # style for top1
        "& \\second{{{txt:.03f}}}",  # style for top2
        "& \\third{{{txt:.03f}}}",  # style for top3
        "& {txt:.03f}",  # style for other
    ],
)


# 排序并添加样式
def replace_cell(ori_value, k):
    if ori_value == IMPOSSIBLE_UP_BOUND or ori_value == IMPOSSIBLE_DOWN_BOUND:
        new_value = "& "
    else:
        new_value = style_templates["body"][k].format(txt=ori_value)
    return new_value


for col, ori_col in zip(column_for_index, ori_columns):
    col_array = np.array(col).reshape(-1).round(args.num_bits)
    sorted_col_array = np.sort(np.unique(col_array), axis=-1)[-3:][::-1]
    # [top1_idxes, top2_idxes, top3_idxes]
    top_k_idxes = [np.argwhere(col_array == x).tolist() for x in sorted_col_array]
    for k, idxes in enumerate(top_k_idxes):
        for row_idx in idxes:
            ori_col[row_idx[0]] = replace_cell(ori_col[row_idx[0]], k)

    for idx, x in enumerate(ori_col):
        if not isinstance(x, str):
            ori_col[idx] = replace_cell(x, -1)

# 构建表头
num_datasets = len(dataset_names)
num_metrics = len(metric_names)
num_methods = len(method_names)

# 先构开头的列，再整体构造开头的行
latex_table_head = []
latex_table_tail = []


def remove_latex_chars_out_of_mathenv(string: str):
    string_splits = string.split("$")  # 'abcd$efg$hij$' -> ['abcd', 'efg', 'hij', '']
    for i, s in enumerate(string_splits):
        if i % 2 == 0:
            string_splits[i] = re.sub(pattern=r"_", repl=r"-", string=s)
    string = "$".join(string_splits)
    return string


method_names = [remove_latex_chars_out_of_mathenv(x) for x in method_names]
dataset_names = [remove_latex_chars_out_of_mathenv(x) for x in dataset_names]
if not args.transpose:
    dataset_row = (
        [style_templates["dataset_head"]]
        + [
            style_templates["dataset_row_body"].format(num_metrics=num_metrics, dataset_name=x)
            for x in dataset_names
        ]
        + [r"\\"]
    )
    metric_row = (
        [style_templates["metric_row_head"]]
        + [style_templates["metric_body"].format(metric_name=x) for x in metric_names]
        * num_datasets
        + [r"\\"]
    )
    additional_rows = [dataset_row, metric_row]

    # 构建第一列
    method_column = [
        style_templates["method_column_body"].format(method_name=x) for x in method_names
    ]
    additional_columns = [method_column]

    columns = additional_columns + ori_columns
    rows = [list(row) + [r"\\"] for row in zip(*columns)]
    rows = additional_rows + rows

    if args.contain_table_env:
        column_style = "|".join([f"*{num_metrics}{{c}}"] * len(dataset_names))
        latex_table_head = [
            f"\\begin{{tabular}}{{l|{column_style}}}\n",
            "\\toprule[2pt]",
        ]
else:
    dataset_column = []
    for x in dataset_names:
        blank_cells = [" "] * (num_metrics - 1)
        dataset_cell = [
            style_templates["dataset_column_body"].format(num_metrics=num_metrics, dataset_name=x)
        ]
        dataset_column.extend(blank_cells + dataset_cell)
    metric_column = [
        style_templates["metric_body"].format(metric_name=x) for x in metric_names
    ] * num_datasets
    additional_columns = [dataset_column, metric_column]

    method_row = (
        [style_templates["dataset_head"], style_templates["metric_column_head"]]
        + [style_templates["method_row_body"].format(method_name=x) for x in method_names]
        + [r"\\"]
    )
    additional_rows = [method_row]

    additional_columns = [list(x) for x in zip(*additional_columns)]
    rows = [cells + row + [r"\\"] for cells, row in zip(additional_columns, ori_columns)]
    rows = additional_rows + rows

    if args.contain_table_env:
        column_style = "".join([f"*{{{num_methods}}}{{c}}"])
        latex_table_head = [
            f"\\begin{{tabular}}{{cc|{column_style}}}\n",
            "\\toprule[2pt]",
        ]

if args.contain_table_env:
    latex_table_tail = [
        "\\bottomrule[2pt]\n",
        "\\end{tabular}",
    ]

rows = [arg_head, latex_table_head] + rows + [latex_table_tail]

with open(args.tex_file, mode="w", encoding="utf-8") as f:
    for row in rows:
        f.write("".join(row) + "\n")
